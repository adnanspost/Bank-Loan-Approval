# Bank-Loan-Approval
Classification/Prediction

Introduction: This project involves solving a binary classification machine learning problem in the Banking & Finance industry.

Aim: The aim of this project is to make accurate predictions from historical data in regards to whether a customer loan application will be approved or not.

Methodology: While the fine details of the methodology followed in this project will be elaborated further in the relevant sections to come, it is to be mentioned that 16 machine learning models have been implemented, compared, and contrasted to identify the best performing one.

### 01. Import CPU Python Libraries
### 02. Function Helper
### 03. Import Dataset & Data Description
- Import CSV File
- Data Description
### 04. Data Understanding
- Data Information
- Data Summary Statistic
- Data Variance
### 05. Select the Featurs
### 06. Data Pre-Processing
- Drop Variables
- Convert Data Type
- Missing Value
### 07. Exploratory Data Analysis
- DV Visualization
- Categorical IDV
- Categorical IDV With DV
- Numerical IDV
- Numerical IDV With DV
### 08. Data Transformation
- Stander Scale
### 9. Feature Selection
- Wrapper - Forward
### 10. Feature Engineering
- LableEncoder
### 11. Statistics
- Correlations IDV with DV
- Correlation between all the Variables
### 12. Resampling Data
- SMOTE
### 13. Data Splitting
### 14. Standard Machine Learning Models
- Build the Models 'Train the Models'
- Random Forest Classifier
- Gradient Boosting Classifier
- Histogram-based Gradient Boosting Classification Tree
- AdaBoost Classifier
- Extra Trees Classifier
- K Neighbors Classifier
- Naive Bayes Classifiers
- Naive Bayes Classifier for Multivariate Bernoulli
- Decision Tree Classifier
- Logistic Regression Classifier
- Logistic Regression CV Classifier
- Stochastic Gradient Descent Classifier
- Linear Perceptron Classifier
- XGBoost Classifiers
- Support Vector Machines Classifiers
- Linear Support Vector Classification
- Multilayer Perceptron Classifier
- Predication X_test
- Models Evaluation
- Accuracy Score
- Classification Report
- Confusion Matrix
### 15. Optmization Machine Learning Models
- random grid for CPU Machine Learning Models
- Hyperparameters for CPU Machine Learning Models
- Build the Models 'Train the Models'
- Random Forest Classifier
- Gradient Boosting Classifier
- Histogram-based Gradient Boosting Classification Tree
- AdaBoost Classifier
- Extra Trees Classifier
- K Neighbors Classifier
- Decision Tree Classifier
- Logistic Regression Classifier
- Logistic Regression CV Classifier
- Stochastic Gradient Descent Classifier
- Linear Perceptron Classifier
- Support Vector Machines Classifiers
- Predication X_test
- Models Evaluation
- Accuracy Score
- Classification Report
- Confusion Matrix
### 16. Accuracy Score and Results:

![MicrosoftTeams-image (24)](https://user-images.githubusercontent.com/108016592/175753761-f163ed1c-2ca5-4c55-8107-ba3b25c7c6c9.png)

![MicrosoftTeams-image (25)](https://user-images.githubusercontent.com/108016592/175753808-d44ebe30-cb41-4dab-bcad-0c38d4b36fb7.png)

Based on the results above, it can be observed that under the Standard Machine Learning models, Logistic Regression Classifier, Linear Support Vector Classification, Logistic Regression CV Classifier achieves the highest accuracy of 90.9 percent, 90.2 percent, and 90.2 percent respectively. The visualizations below depict the performance of the models after goingt through the optimization process.

![MicrosoftTeams-image (26)](https://user-images.githubusercontent.com/108016592/175753956-91f5009d-5c9f-4ba7-b689-8f2670095454.png)

![MicrosoftTeams-image (27)](https://user-images.githubusercontent.com/108016592/175753971-4509bde2-0616-4dd6-805b-e210e6162c84.png)

As it can be observed above, the results after the optimization process shows improvement in the model performance and the Logistic Regression Classifier, Extra Trees Classifier, AdaBoost Classifier consist of the highest accuracy of 92.8 percent, 92.2 percent, and 91.5 percent respectively.

Results: 

The table above provides is a comparison of the Accuracy of the Standard CPU Models vs the Accuracy of the Optimized CPU Models. As it is can be seen, the accuracy for 'Logistic Regression Classifier', 'Random Forest Classifier', 'Linear Perceptron Classifier', 'Gradient Boosting Classifier', 'AdaBoost Classifier', 'Histogram-based Gradient Boosting Classification Tree' , 'Stochastic Gradient Descent Classifier', 'Extra Trees Classifier' experienced an increase between the range of 1% and 4% for each model mentioned.

![MicrosoftTeams-image (28)](https://user-images.githubusercontent.com/108016592/175754332-41103058-f5b7-436e-b474-60f307917129.png)

